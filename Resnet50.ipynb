{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --pre pytorch-ignite==0.5.0.dev20230325\n",
    "!pip install -q fastbook==0.0.29\n",
    "!pip install --upgrade -q mxnet==1.9.1\n",
    "!pip install -q autogluon==0.7.0\n",
    "!pip install -q pythainlp==3.1.1\n",
    "!pip install -q transformers==4.27.3\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "\n",
    "from ignite.engine import Engine, Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "\n",
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "except ImportError:\n",
    "    try:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "    except ImportError:\n",
    "        raise RuntimeError(\n",
    "            \"This module requires either tensorboardX or torch >= 1.2.0. \"\n",
    "            \"You may install tensorboardX with command: \\n pip install tensorboardX \\n\"\n",
    "            \"or upgrade PyTorch using your package manager of choice (pip or conda).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.tensor([[0.4, 0.6],\n",
    "                      [0.1, 0.9],\n",
    "                      [0.9, 0.1]], dtype=torch.float)\n",
    "preds = probs.argmax(1)\n",
    "targets = torch.tensor([0,1,0])\n",
    "\n",
    "print(probs)\n",
    "print(preds)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbd9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "(preds==targets).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/content/dataset/train'\n",
    "valid_dir = '/content/dataset/val'\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop((224,224),scale=(0.5,1.2)),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "valid_transform = T.Compose([\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "#dataset\n",
    "train_ds = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "valid_ds = datasets.ImageFolder(valid_dir, transform=valid_transform)\n",
    "\n",
    "#dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "\n",
    "classes = train_ds.classes\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e7d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "#helper functions from https://pytorch.org/vision/master/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
    "def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, \n",
    "                            squeeze=False,)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_img] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "test_images = glob.glob('/content/10cls/test/Boat_noodle/064fd7c6-c793-4b41-9faf-801e816a1fad.jpg')\n",
    "i = np.random.randint(0,len(test_images))\n",
    "orig_img = Image.open(test_images[i])\n",
    "\n",
    "augmenter = T.TrivialAugmentWide()\n",
    "imgs = [augmenter(orig_img) for _ in range(2)]\n",
    "plot(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions adapted from https://pytorch.org/vision/master/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
    "def plot_row(imgs, img_per_row = 3):\n",
    "    num_cols = img_per_row\n",
    "    num_rows = len(imgs) // num_cols\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        ax = axs[row_idx // num_cols, row_idx % num_cols]\n",
    "        ax.imshow(row.permute(1,2,0))\n",
    "        ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "sample_imgs = next(iter(train_dl))\n",
    "plot_row(sample_imgs[0][:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ddd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = models.resnet50(pretrained=True)\n",
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afb179",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.tensor([[0.4, 0.6],\n",
    "                      [0.1, 0.9],\n",
    "                      [0.9, 0.1]], dtype=torch.float)\n",
    "preds = probs.argmax(1)\n",
    "targets = torch.tensor([0,1,0])\n",
    "\n",
    "print(probs)\n",
    "print(preds)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde36807",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.tensor([[0.4, 0.6],\n",
    "                      [0.1, 0.9],\n",
    "                      [0.9, 0.1]], dtype=torch.float)\n",
    "preds = probs.argmax(1)\n",
    "targets = torch.tensor([0,1,0])\n",
    "\n",
    "print(probs)\n",
    "print(preds)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "(preds==targets).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7059de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(backbone.parameters(), lr=3e-4)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e9aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = FoodResNet(n_classes=len(train_ds.classes)).to(device)\n",
    "\n",
    "#loss\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "#trainer\n",
    "trainer = create_supervised_trainer(model, optimizer, loss_function, device=device)\n",
    "\n",
    "#metric\n",
    "val_metrics = {\"accuracy\": Accuracy(), \"ce_loss\": Loss(loss_function)}\n",
    "evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logger\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "train_log_interval = 1 \n",
    "eval_log_interval = len(train_dl) #1 epoch = จำนวน example ทั้งหมด / batch size = วนครบทุก example 1 รอบ\n",
    "\n",
    "pbar = tqdm(initial=0, \n",
    "            leave=False, \n",
    "            total=len(train_dl), \n",
    "            desc=f\"epoch {0} - loss: {0:.4f} - lr: {0:.4f}\")\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=train_log_interval))\n",
    "def log_training_loss(engine):\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    pbar.desc = f\"epoch {engine.state.epoch} - train loss: {engine.state.output:.4f} - lr: {lr:.4f}\"\n",
    "    pbar.update(train_log_interval)\n",
    "    writer.add_scalar(\"training/loss\", engine.state.output, engine.state.iteration)\n",
    "\n",
    "#ทุก epoch, บันทึก training loss, accuracy\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=eval_log_interval))\n",
    "def log_training_results(engine):\n",
    "    evaluator.run(train_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics[\"accuracy\"]\n",
    "    avg_loss = metrics[\"ce_loss\"]\n",
    "    tqdm.write(\n",
    "        f\"train results - epoch: {engine.state.epoch} avg accuracy: {avg_accuracy:.2f} avg loss: {avg_loss:.2f}\"\n",
    "    )\n",
    "    writer.add_scalar(\"training/avg_loss\", avg_loss, engine.state.iteration)\n",
    "    writer.add_scalar(\"training/avg_accuracy\", avg_accuracy, engine.state.iteration)\n",
    "\n",
    "#ทุก epoch, บันทึก validation loss, accuracy\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=eval_log_interval))\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(valid_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics[\"accuracy\"]\n",
    "    avg_loss = metrics[\"ce_loss\"]\n",
    "    tqdm.write(\n",
    "        f\"valid results - epoch: {engine.state.epoch} avg accuracy: {avg_accuracy:.2f} avg loss: {avg_loss:.2f}\"\n",
    "    )\n",
    "    writer.add_scalar(\"valdation/avg_loss\", avg_loss, engine.state.iteration)\n",
    "    writer.add_scalar(\"valdation/avg_accuracy\", avg_accuracy, engine.state.iteration)\n",
    "    pbar.n = pbar.last_print_n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b02709",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(train_dl, max_epochs=20)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9f6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
